import json
import boto3
import os
import uuid
import urllib.request
import urllib.parse
from datetime import datetime
from typing import Dict, List, Optional, Any
import time
import logging

# ãƒ­ã‚°è¨­å®š
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MeetingMinutesProcessor:
    """è­°äº‹éŒ²å‡¦ç†ãƒ¡ã‚¤ãƒ³ã‚¯ãƒ©ã‚¹"""

    def __init__(self):
        """AWS ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆåˆæœŸåŒ–"""
        self.s3_client = boto3.client('s3')
        self.transcribe_client = boto3.client('transcribe')
        self.bedrock_client = boto3.client('bedrock-runtime', region_name='us-east-1')
        
        # è¨­å®šå€¤
        self.max_file_size = 100 * 1024 * 1024  # 100MB
        self.max_transcript_length = 8000
        self.audio_extensions = {'.mp3', '.wav', '.m4a', '.mp4', '.ogg', '.flac', '.aac'}
        
        # æŒ‡å®šã•ã‚ŒãŸClaude ãƒ¢ãƒ‡ãƒ«IDï¼ˆæœ€å„ªå…ˆè¨­å®šï¼‰
        self.primary_model = "anthropic.claude-sonnet-4-20250514-v1:0"  # æŒ‡å®šã•ã‚ŒãŸãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«
        
        self.claude_models = [
            "anthropic.claude-sonnet-4-20250514-v1:0",         # ğŸ¥‡ æŒ‡å®šã•ã‚ŒãŸãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«
            "anthropic.claude-3-5-sonnet-20241022-v2:0",       # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯1
            "anthropic.claude-3-5-sonnet-20240620-v1:0",       # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯2
            "anthropic.claude-3-sonnet-20240229-v1:0",         # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯3
            "anthropic.claude-3-haiku-20240307-v1:0"           # ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯4
        ]
        
        logger.info("=== MeetingMinutesProcessoråˆæœŸåŒ– ===")
        logger.info(f"ğŸ¥‡ æŒ‡å®šãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«: {self.primary_model}")
        logger.info(f"ğŸ”„ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«æ•°: {len(self.claude_models) - 1}")

    def process_event(self, event: Dict[str, Any], context: Any) -> Dict[str, Any]:
        """ãƒ¡ã‚¤ãƒ³ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†"""
        logger.info("=== è‡ªå‹•è­°äº‹éŒ²ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ é–‹å§‹ ===")
        logger.info(f"ä½¿ç”¨äºˆå®šãƒ¢ãƒ‡ãƒ«: {self.primary_model}")
        
        try:
            # ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ç¢ºèª
            self._create_system_status_log(event, context)
            
            # å®Ÿè¡Œæ™‚é–“ãƒã‚§ãƒƒã‚¯
            remaining_time = context.get_remaining_time_in_millis()
            logger.info(f"Lambdaå®Ÿè¡Œå¯èƒ½æ™‚é–“: {remaining_time/1000:.1f}ç§’")
            
            # S3ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†
            if 'Records' in event and event['Records']:
                return self._process_s3_events(event['Records'], context)
            else:
                # æ‰‹å‹•å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰
                return self._process_manual_mode(context)
                
        except Exception as e:
            logger.error(f"ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼: {str(e)}", exc_info=True)
            self._create_error_debug_file(str(e), e)
            return self._create_error_response(str(e), 500)

    def _create_system_status_log(self, event: Dict[str, Any], context: Any) -> None:
        """ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ãƒ­ã‚°ä½œæˆ"""
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            status_key = f"system_logs/system_status_{timestamp}.txt"
            
            status_content = f"""=== è­°äº‹éŒ²ç”Ÿæˆã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ ===

å®Ÿè¡Œæ™‚åˆ»: {datetime.now().isoformat()}
Lambdaé–¢æ•°: {context.function_name}
ãƒ¡ãƒ¢ãƒªåˆ¶é™: {context.memory_limit_in_mb}MB
å®Ÿè¡Œæ™‚é–“åˆ¶é™: {context.get_remaining_time_in_millis()/1000:.1f}ç§’

ğŸ¥‡ æŒ‡å®šãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«:
{self.primary_model}

ğŸ”„ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯è¨­å®š:
"""

            for i, model in enumerate(self.claude_models[1:], 2):
                status_content += f"{i}. {model}\n"
            
            status_content += f"""

ã€Bedrockã‚¢ã‚¯ã‚»ã‚¹ç¢ºèªãŒå¿…è¦ã€‘
ä»¥ä¸‹ã®ãƒ¢ãƒ‡ãƒ«ãŒ 'Access granted' ã«ãªã£ã¦ã„ã‚‹ã‹ç¢ºèªã—ã¦ãã ã•ã„:

æœ€é‡è¦:
â–¡ {self.primary_model}

ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ç”¨:
â–¡ {self.claude_models[1]}
â–¡ {self.claude_models[2]}
â–¡ {self.claude_models[3]}
â–¡ {self.claude_models[4]}

ã€ç¢ºèªæ–¹æ³•ã€‘
AWS Bedrock â†’ Model access â†’ å„ãƒ¢ãƒ‡ãƒ«ã®Statusç¢ºèª

ã€ç”³è«‹æ–¹æ³•ã€‘
Status ãŒ 'Available to request' ã®å ´åˆ:
1. 'Request model access' ã‚’ã‚¯ãƒªãƒƒã‚¯
2. Use case: 'General'
3. Submit

å—ä¿¡ã‚¤ãƒ™ãƒ³ãƒˆ:
{json.dumps(event, indent=2, ensure_ascii=False)}
"""

            self.s3_client.put_object(
                Bucket="followup-mail",
                Key=status_key,
                Body=status_content.encode('utf-8'),
                ContentType='text/plain; charset=utf-8'
            )
            logger.info(f"âœ… ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ãƒ­ã‚°ä½œæˆ: s3://followup-mail/{status_key}")
            
        except Exception as e:
            logger.warning(f"âš ï¸ ã‚·ã‚¹ãƒ†ãƒ çŠ¶æ…‹ãƒ­ã‚°ä½œæˆå¤±æ•—: {str(e)}")

    def _process_s3_events(self, records: List[Dict[str, Any]], context: Any) -> Dict[str, Any]:
        """S3ã‚¤ãƒ™ãƒ³ãƒˆå‡¦ç†"""
        results = []
        
        for record in records:
            if record.get('eventSource') != 'aws:s3':
                continue
                
            bucket_name = record['s3']['bucket']['name']
            object_key = urllib.parse.unquote_plus(record['s3']['object']['key'])
            
            logger.info(f"ğŸµ å‡¦ç†å¯¾è±¡ãƒ•ã‚¡ã‚¤ãƒ«: s3://{bucket_name}/{object_key}")
            
            if self._is_valid_audio_file(object_key):
                result = self._process_single_audio_file(bucket_name, object_key, context)
                results.append(result)
            else:
                logger.info(f"â­ï¸ ã‚¹ã‚­ãƒƒãƒ—: {object_key} (ç„¡åŠ¹ãªãƒ•ã‚¡ã‚¤ãƒ«)")
        
        return self._create_success_response(results)

    def _process_manual_mode(self, context: Any) -> Dict[str, Any]:
        """æ‰‹å‹•å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰"""
        logger.info("ğŸ”§ æ‰‹å‹•å®Ÿè¡Œãƒ¢ãƒ¼ãƒ‰ - æœ€æ–°ã®MP3ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‡¦ç†")
        
        try:
            bucket_name = "followup-mail"
            audio_prefix = "meeting record/"
            
            latest_file = self._find_latest_audio_file(bucket_name, audio_prefix)
            if not latest_file:
                return self._create_error_response("éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“", 404)
            
            result = self._process_single_audio_file(bucket_name, latest_file['Key'], context)
            
            return {
                'statusCode': 200,
                'body': json.dumps({
                    'mode': 'manual',
                    'result': result
                }, ensure_ascii=False, indent=2)
            }
            
        except Exception as e:
            logger.error(f"æ‰‹å‹•ãƒ¢ãƒ¼ãƒ‰ã‚¨ãƒ©ãƒ¼: {str(e)}", exc_info=True)
            return self._create_error_response(str(e), 500)

    def _is_valid_audio_file(self, object_key: str) -> bool:
        """æœ‰åŠ¹ãªéŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ãƒã‚§ãƒƒã‚¯"""
        if not object_key.startswith('meeting record/'):
            return False
        
        return any(object_key.lower().endswith(ext) for ext in self.audio_extensions)

    def _find_latest_audio_file(self, bucket_name: str, prefix: str) -> Optional[Dict[str, Any]]:
        """æœ€æ–°ã®éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œç´¢"""
        try:
            response = self.s3_client.list_objects_v2(Bucket=bucket_name, Prefix=prefix)
            
            if 'Contents' not in response:
                return None
            
            audio_files = [
                obj for obj in response['Contents'] 
                if self._is_valid_audio_file(obj['Key'])
            ]
            
            if not audio_files:
                return None
            
            return max(audio_files, key=lambda x: x['LastModified'])
            
        except Exception as e:
            logger.error(f"éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«æ¤œç´¢ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None

    def _process_single_audio_file(self, bucket_name: str, object_key: str, context: Any) -> Dict[str, Any]:
        """å˜ä¸€éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ï¼ˆæ›´æ–°ç‰ˆï¼‰"""
        logger.info(f"ğŸµ éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†é–‹å§‹: {object_key}")
        logger.info(f"ğŸ¥‡ ä½¿ç”¨äºˆå®šãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«: {self.primary_model}")
        
        try:
            # ãƒ•ã‚¡ã‚¤ãƒ«æƒ…å ±å–å¾—
            file_info = self.s3_client.head_object(Bucket=bucket_name, Key=object_key)
            file_size = file_info['ContentLength']
            last_modified = file_info['LastModified']
            
            logger.info(f"ğŸ“ ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚º: {file_size/1024/1024:.2f}MB")
            
            # ã‚µã‚¤ã‚ºãƒã‚§ãƒƒã‚¯
            if file_size > self.max_file_size:
                return self._create_file_error_result(object_key, "ãƒ•ã‚¡ã‚¤ãƒ«ã‚µã‚¤ã‚ºãŒ100MBã‚’è¶…ãˆã¦ã„ã¾ã™")
            
            # å‡¦ç†é€²æ—ã‚’S3ã«è¨˜éŒ²
            self._create_progress_file(object_key, f"æ–‡å­—èµ·ã“ã—å‡¦ç†é–‹å§‹ (ä½¿ç”¨äºˆå®šãƒ¢ãƒ‡ãƒ«: {self.primary_model})")
            
            # ä¼šè­°æƒ…å ±ç”Ÿæˆ
            meeting_info = self._generate_meeting_info(object_key, last_modified)
            logger.info(f"ğŸ“ ä¼šè­°æƒ…å ±: {meeting_info['title']}")
            
            # æ–‡å­—èµ·ã“ã—å‡¦ç†
            transcript_result = self._process_transcription(bucket_name, object_key, context)
            if transcript_result['status'] != 'success':
                # æ–‡å­—èµ·ã“ã—å¤±æ•—æ™‚ã‚‚ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ã§ç¶šè¡Œ
                logger.warning("æ–‡å­—èµ·ã“ã—å¤±æ•— - ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ã§ç¶šè¡Œ")
                transcript_text = self._get_demo_transcript()
                self._create_progress_file(object_key, "æ–‡å­—èµ·ã“ã—å¤±æ•— - ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨")
            else:
                transcript_text = transcript_result['transcript']
                logger.info(f"âœ… æ–‡å­—èµ·ã“ã—å®Œäº†: {len(transcript_text)}æ–‡å­—")
                self._create_progress_file(object_key, f"æ–‡å­—èµ·ã“ã—å®Œäº† ({len(transcript_text)}æ–‡å­—)")
            
            # Claudeå‡¦ç†é€²æ—æ›´æ–°
            self._create_progress_file(object_key, f"Claudeå‡¦ç†é–‹å§‹ (ãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«: {self.primary_model})")
            
            # è­°äº‹éŒ²ç”Ÿæˆï¼ˆæŒ‡å®šãƒ¢ãƒ‡ãƒ«æœ€å„ªå…ˆï¼‰
            summary_result = self._generate_meeting_summary_with_specified_model(meeting_info, transcript_text, object_key)
            if not summary_result:
                # å…¨ãƒ¢ãƒ‡ãƒ«å¤±æ•—æ™‚ã¯ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ã§ç¶šè¡Œ
                logger.warning("å…¨Claudeãƒ¢ãƒ‡ãƒ«å¤±æ•— - ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ã§ç¶šè¡Œ")
                summary_result = self._create_demo_summary(meeting_info, transcript_text)
                self._create_progress_file(object_key, f"å…¨Claudeãƒ¢ãƒ‡ãƒ«å¤±æ•— (ãƒ¡ã‚¤ãƒ³: {self.primary_model}) - ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨")
            else:
                self._create_progress_file(object_key, f"Claudeå‡¦ç†å®Œäº† (ä½¿ç”¨ãƒ¢ãƒ‡ãƒ«è¨˜éŒ²æ¸ˆã¿)")
            
            # ä¼šè­°æƒ…å ±ã‚’ã‚µãƒãƒªãƒ¼ã«è¿½åŠ ï¼ˆãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆç”¨ï¼‰
            summary_result["meeting_title"] = meeting_info['title']
            summary_result["meeting_date"] = meeting_info['date']
            summary_result["participants"] = meeting_info['participants']
            
            # ãƒ¡ãƒ¼ãƒ«ã‚³ãƒ”ãƒšç”¨ãƒ†ã‚­ã‚¹ãƒˆä½œæˆ
            self._create_progress_file(object_key, "ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆé–‹å§‹")
            copy_paste_text = self._create_copy_paste_text(summary_result, meeting_info, object_key, transcript_text)
            
            # æ–°ã—ã„ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜æ–¹å¼ã§ä¿å­˜
            saved_files = self._save_text_files_to_email_output(bucket_name, object_key, transcript_text, summary_result, copy_paste_text)
            
            # å®Œäº†é€šçŸ¥ä½œæˆ
            self._create_completion_notification(bucket_name, object_key, meeting_info, len(transcript_text), saved_files)
            
            # æœ€çµ‚é€²æ—
            self._create_progress_file(object_key, "âœ… å…¨å‡¦ç†å®Œäº† - æ¨™æº–ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã®ãƒ•ã‚¡ã‚¤ãƒ«ç”Ÿæˆæ¸ˆã¿")
            
            # Get manifest path if available
            manifest_path = saved_files.get("manifest", "")
            
            return {
                'file': object_key,
                'status': 'success',
                'primary_model_used': self.primary_model,
                'meeting_info': meeting_info,
                'transcript_length': len(transcript_text),
                'text_files_created': True,
                'output_folder': f"email_output/{object_key.split('/')[-1].rsplit('.', 1)[0]}/",
                'manifest': manifest_path,
                'processing_time': datetime.now().isoformat()
            }
            
        except Exception as e:
            logger.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼ ({object_key}): {str(e)}", exc_info=True)
            self._create_progress_file(object_key, f"âŒ å‡¦ç†ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return self._create_file_error_result(object_key, str(e))

    def _create_progress_file(self, object_key: str, status: str) -> None:
        """é€²æ—ã‚’ãƒ•ã‚¡ã‚¤ãƒ«ã«è¨˜éŒ²ï¼ˆæ–°ã—ã„ãƒ•ã‚©ãƒ«ãƒ€æ§‹é€ ã«å¯¾å¿œï¼‰"""
        try:
            # Extract filename for folder name
            audio_filename = object_key.split('/')[-1].rsplit('.', 1)[0]
            timestamp = datetime.now().strftime('%H:%M:%S')
            progress_key = f"email_output/{audio_filename}/progress.txt"
            
            # Get existing content or create new
            try:
                existing = self.s3_client.get_object(Bucket="followup-mail", Key=progress_key)
                existing_content = existing['Body'].read().decode('utf-8')
            except:
                existing_content = f"""=== å‡¦ç†é€²æ—: {audio_filename} ===

é–‹å§‹æ™‚åˆ»: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}
æŒ‡å®šãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«: {self.primary_model}
å‡¦ç†ãƒ¢ãƒ¼ãƒ‰: ãƒ†ã‚­ã‚¹ãƒˆãƒ•ã‚¡ã‚¤ãƒ«å‡ºåŠ›å°‚ç”¨

"""

            new_content = existing_content + f"[{timestamp}] {status}\n"
            
            self.s3_client.put_object(
                Bucket="followup-mail",
                Key=progress_key,
                Body=new_content.encode('utf-8'),
                ContentType='text/plain; charset=utf-8'
            )
            
        except Exception as e:
            logger.warning(f"é€²æ—è¨˜éŒ²å¤±æ•—: {str(e)}")

    def _generate_meeting_info(self, object_key: str, last_modified: datetime) -> Dict[str, str]:
        """ä¼šè­°æƒ…å ±ç”Ÿæˆ"""
        filename = object_key.split('/')[-1].rsplit('.', 1)[0]
        
        # ãƒ•ã‚¡ã‚¤ãƒ«åã‹ã‚‰ä¼šè­°ã‚¿ã‚¤ãƒˆãƒ«ã‚’æ¨æ¸¬
        if 'GMT' in filename:
            meeting_title = "å®šæœŸä¼šè­° (è‡ªå‹•æ¤œå‡º)"
        elif 'meeting' in filename.lower():
            meeting_title = f"ä¼šè­°éŒ²éŸ³ - {filename}"
        else:
            meeting_title = f"éŸ³å£°ä¼šè­° - {filename}"
        
        return {
            'title': meeting_title,
            'date': last_modified.strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M'),
            'participants': "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è‡ªå‹•æ¤œå‡º",
            'source_file': object_key
        }

    def _process_transcription(self, bucket_name: str, object_key: str, context: Any) -> Dict[str, Any]:
        """æ–‡å­—èµ·ã“ã—å‡¦ç†"""
        logger.info("ğŸ¤ æ–‡å­—èµ·ã“ã—å‡¦ç†é–‹å§‹")
        
        try:
            # æ—¢å­˜æ–‡å­—èµ·ã“ã—ãƒã‚§ãƒƒã‚¯
            existing_transcript = self._check_existing_transcript(bucket_name, object_key)
            if existing_transcript:
                logger.info("ğŸ“„ æ—¢å­˜ã®æ–‡å­—èµ·ã“ã—ã‚’ä½¿ç”¨")
                return {
                    'status': 'success',
                    'transcript': existing_transcript,
                    'source': 'existing'
                }
            
            # æ–°è¦æ–‡å­—èµ·ã“ã—å®Ÿè¡Œ
            transcript_text = self._execute_transcription(bucket_name, object_key, context)
            
            if transcript_text:
                self._save_transcript(bucket_name, object_key, transcript_text)
                return {
                    'status': 'success',
                    'transcript': transcript_text,
                    'source': 'new'
                }
            else:
                return {
                    'status': 'error',
                    'message': 'Transcribeå‡¦ç†ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ'
                }
                
        except Exception as e:
            logger.error(f"æ–‡å­—èµ·ã“ã—ã‚¨ãƒ©ãƒ¼: {str(e)}", exc_info=True)
            return {
                'status': 'error',
                'message': f'æ–‡å­—èµ·ã“ã—ã‚¨ãƒ©ãƒ¼: {str(e)}'
            }

    def _check_existing_transcript(self, bucket_name: str, audio_key: str) -> Optional[str]:
        """æ—¢å­˜æ–‡å­—èµ·ã“ã—ãƒã‚§ãƒƒã‚¯"""
        try:
            audio_filename = audio_key.split('/')[-1].rsplit('.', 1)[0]
            transcript_key = f"transcripts/{audio_filename}_transcript.txt"
            
            response = self.s3_client.get_object(Bucket=bucket_name, Key=transcript_key)
            transcript_text = response['Body'].read().decode('utf-8')
            logger.info(f"âœ… æ—¢å­˜æ–‡å­—èµ·ã“ã—ç™ºè¦‹: {transcript_key}")
            return transcript_text
            
        except self.s3_client.exceptions.NoSuchKey:
            return None
        except Exception as e:
            logger.warning(f"æ—¢å­˜æ–‡å­—èµ·ã“ã—ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None

    def _execute_transcription(self, bucket_name: str, object_key: str, context: Any) -> Optional[str]:
        """Transcribeå®Ÿè¡Œ"""
        try:
            # ã‚¸ãƒ§ãƒ–è¨­å®š
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            job_name = f"auto-meeting-{timestamp}-{uuid.uuid4().hex[:8]}"
            
            # ãƒ•ã‚¡ã‚¤ãƒ«å½¢å¼åˆ¤å®š
            file_extension = object_key.lower().split('.')[-1]
            format_mapping = {
                'mp3': 'mp3', 'wav': 'wav', 'm4a': 'mp4', 'mp4': 'mp4',
                'ogg': 'ogg', 'flac': 'flac', 'aac': 'mp4'
            }
            media_format = format_mapping.get(file_extension, 'mp3')
            
            audio_url = f"s3://{bucket_name}/{object_key}"
            
            logger.info(f"ğŸ™ï¸ Transcribeã‚¸ãƒ§ãƒ–é–‹å§‹: {job_name} ({media_format})")
            
            # ã‚¸ãƒ§ãƒ–é–‹å§‹
            self.transcribe_client.start_transcription_job(
                TranscriptionJobName=job_name,
                Media={'MediaFileUri': audio_url},
                MediaFormat=media_format,
                LanguageCode='ja-JP',
                Settings={
                    'ShowSpeakerLabels': True,
                    'MaxSpeakerLabels': 10
                }
            )
            
            # å®Œäº†å¾…æ©Ÿ
            return self._wait_for_transcription(job_name, context)
            
        except Exception as e:
            logger.error(f"Transcribeå®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {str(e)}", exc_info=True)
            return None

    def _wait_for_transcription(self, job_name: str, context: Any) -> Optional[str]:
        """Transcribeå®Œäº†å¾…æ©Ÿ"""
        remaining_time = context.get_remaining_time_in_millis()
        max_wait_seconds = min(600, max(60, (remaining_time / 1000) - 180))
        max_attempts = int(max_wait_seconds // 20)
        
        logger.info(f"â±ï¸ æœ€å¤§å¾…æ©Ÿæ™‚é–“: {max_wait_seconds:.0f}ç§’")
        
        for attempt in range(max_attempts):
            try:
                response = self.transcribe_client.get_transcription_job(TranscriptionJobName=job_name)
                job_status = response['TranscriptionJob']['TranscriptionJobStatus']
                
                logger.info(f"ğŸ“Š ã‚¸ãƒ§ãƒ–çŠ¶æ…‹ç¢ºèª ({attempt+1}/{max_attempts}): {job_status}")
                
                if job_status == 'COMPLETED':
                    transcript_uri = response['TranscriptionJob']['Transcript']['TranscriptFileUri']
                    transcript_text = self._fetch_transcript_result(transcript_uri)
                    self._cleanup_transcribe_job(job_name)
                    return transcript_text
                
                elif job_status == 'FAILED':
                    failure_reason = response['TranscriptionJob'].get('FailureReason', 'ä¸æ˜')
                    logger.error(f"âŒ æ–‡å­—èµ·ã“ã—å¤±æ•—: {failure_reason}")
                    self._cleanup_transcribe_job(job_name)
                    return None
                
                # æ®‹ã‚Šæ™‚é–“ãƒã‚§ãƒƒã‚¯
                remaining = context.get_remaining_time_in_millis()
                if remaining < 120000:  # 2åˆ†ä»¥ä¸‹ã®å ´åˆ
                    logger.warning(f"âš ï¸ Lambdaå®Ÿè¡Œæ™‚é–“æ®‹ã‚Šå°‘ãªã ({remaining/1000:.1f}ç§’)ã€å¼·åˆ¶çµ‚äº†")
                    self._cleanup_transcribe_job(job_name)
                    return None
                
                # å¾…æ©Ÿ
                time.sleep(20)
                
            except Exception as e:
                logger.error(f"ã‚¸ãƒ§ãƒ–çŠ¶æ…‹ãƒã‚§ãƒƒã‚¯ã‚¨ãƒ©ãƒ¼: {str(e)}")
                break
        
        # ã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ
        logger.warning(f"âš ï¸ Transcribeã‚¸ãƒ§ãƒ–å¾…æ©Ÿã‚¿ã‚¤ãƒ ã‚¢ã‚¦ãƒˆ: {job_name}")
        return None

    def _fetch_transcript_result(self, transcript_uri: str) -> Optional[str]:
        """æ–‡å­—èµ·ã“ã—çµæœå–å¾—"""
        try:
            with urllib.request.urlopen(transcript_uri) as response:
                transcript_json = json.loads(response.read().decode('utf-8'))
            
            # åŸºæœ¬æ–‡å­—èµ·ã“ã—
            transcript = transcript_json.get('results', {}).get('transcripts', [{}])[0].get('transcript', '')
            
            # è©±è€…ãƒ©ãƒ™ãƒ«ä»˜ããƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆè©¦è¡Œ
            items = transcript_json.get('results', {}).get('items', [])
            speakers = transcript_json.get('results', {}).get('speaker_labels', {}).get('speakers', 0)
            
            if items and speakers > 0:
                formatted = self._format_with_speakers(transcript_json)
                if formatted:
                    logger.info("ğŸ—£ï¸ è©±è€…ãƒ©ãƒ™ãƒ«ä»˜ããƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆé©ç”¨")
                    return formatted
            
            logger.info("ğŸ“ åŸºæœ¬ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆä½¿ç”¨")
            return transcript
            
        except Exception as e:
            logger.error(f"æ–‡å­—èµ·ã“ã—çµæœå–å¾—ã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None

    def _format_with_speakers(self, transcript_json: Dict[str, Any]) -> Optional[str]:
        """è©±è€…ãƒ©ãƒ™ãƒ«ä»˜ããƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        try:
            items = transcript_json.get('results', {}).get('items', [])
            speaker_labels = transcript_json.get('results', {}).get('speaker_labels', {})
            segments = speaker_labels.get('segments', [])
            
            # ãƒãƒƒãƒ”ãƒ³ã‚°ä½œæˆ
            time_to_speaker = {}
            for segment in segments:
                speaker_label = segment.get('speaker_label')
                for item in segment.get('items', []):
                    start_time = item.get('start_time')
                    if start_time and speaker_label:
                        time_to_speaker[start_time] = speaker_label
            
            # ç™ºè¨€ãƒ†ã‚­ã‚¹ãƒˆæ§‹ç¯‰
            current_speaker = None
            formatted_transcript = []
            buffer = ""
            
            for item in items:
                if item.get('type') == 'pronunciation':
                    start_time = item.get('start_time')
                    speaker = time_to_speaker.get(start_time)
                    
                    if speaker and speaker != current_speaker and buffer:
                        if current_speaker:
                            formatted_transcript.append(f"è©±è€…{current_speaker.replace('spk_', '')}: {buffer.strip()}")
                        buffer = ""
                        current_speaker = speaker
                    
                    if not current_speaker:
                        current_speaker = speaker
                    
                    content = item.get('alternatives', [{}])[0].get('content', '')
                    buffer += content + " "
                    
                elif item.get('type') == 'punctuation':
                    content = item.get('alternatives', [{}])[0].get('content', '')
                    buffer = buffer.rstrip() + content + " "
            
            # æœ€å¾Œã®ç™ºè¨€ã‚’è¿½åŠ 
            if current_speaker and buffer:
                formatted_transcript.append(f"è©±è€…{current_speaker.replace('spk_', '')}: {buffer.strip()}")
            
            return "\n\n".join(formatted_transcript)
            
        except Exception as e:
            logger.error(f"è©±è€…ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None

    def _cleanup_transcribe_job(self, job_name: str) -> None:
        """Transcribeã‚¸ãƒ§ãƒ–ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—"""
        try:
            self.transcribe_client.delete_transcription_job(TranscriptionJobName=job_name)
            logger.info(f"ğŸ—‘ï¸ Transcribeã‚¸ãƒ§ãƒ–å‰Šé™¤: {job_name}")
        except Exception as e:
            logger.warning(f"ã‚¸ãƒ§ãƒ–å‰Šé™¤å¤±æ•— ({job_name}): {str(e)}")

    def _save_transcript(self, bucket_name: str, audio_key: str, transcript_text: str) -> None:
        """æ–‡å­—èµ·ã“ã—ä¿å­˜"""
        try:
            audio_filename = audio_key.split('/')[-1].rsplit('.', 1)[0]
            transcript_key = f"transcripts/{audio_filename}_transcript.txt"
            
            self.s3_client.put_object(
                Bucket=bucket_name,
                Key=transcript_key,
                Body=transcript_text.encode('utf-8'),
                ContentType='text/plain; charset=utf-8'
            )
            logger.info(f"ğŸ’¾ æ–‡å­—èµ·ã“ã—ä¿å­˜: s3://{bucket_name}/{transcript_key}")
            
        except Exception as e:
            logger.warning(f"æ–‡å­—èµ·ã“ã—ä¿å­˜å¤±æ•—: {str(e)}")

    def _get_demo_transcript(self) -> str:
        """ãƒ‡ãƒ¢æ–‡å­—èµ·ã“ã—ãƒ‡ãƒ¼ã‚¿"""
        return """è©±è€…1: çš†ã•ã‚“ã€ãŠç–²ã‚Œæ§˜ã§ã™ã€‚ãã‚Œã§ã¯ã€Project Xã®é€²æ—ä¼šè­°ã‚’å§‹ã‚ã•ã›ã¦ã„ãŸã ãã¾ã™ã€‚ã¾ãšã€å±±ç”°ã•ã‚“ã‹ã‚‰é–‹ç™ºçŠ¶æ³ã‚’ãŠèã‹ã›ãã ã•ã„ã€‚

è©±è€…2: ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã™ã€å±±ç”°ã§ã™ã€‚ä»Šé€±ã®é–‹ç™ºçŠ¶æ³ã«ã¤ã„ã¦ã”å ±å‘Šã„ãŸã—ã¾ã™ã€‚ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ã®å®Ÿè£…ãŒç´„80%å®Œäº†ã—ã¦ãŠã‚Šã€äºˆå®šé€šã‚Šä»Šæœˆæœ«ã«ã¯ãƒ™ãƒ¼ã‚¿ç‰ˆãŒãƒªãƒªãƒ¼ã‚¹ã§ãã‚‹è¦‹è¾¼ã¿ã§ã™ã€‚ãŸã ã—ã€APIã®çµ±åˆéƒ¨åˆ†ã§ä¸€éƒ¨èª²é¡ŒãŒç™ºç”Ÿã—ã¦ãŠã‚Šã¾ã™ã€‚

è©±è€…1: ã©ã®ã‚ˆã†ãªèª²é¡Œã§ã—ã‚‡ã†ã‹ï¼Ÿ

è©±è€…2: ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã¨ã®é€£æºéƒ¨åˆ†ã§ã€ãƒ¬ã‚¹ãƒãƒ³ã‚¹æ™‚é–“ãŒäºˆæƒ³ã‚ˆã‚Šé•·ããªã£ã¦ã„ã‚‹å•é¡ŒãŒã‚ã‚Šã¾ã™ã€‚æœ€é©åŒ–ãŒå¿…è¦ãªçŠ¶æ³ã§ã™ã€‚

è©±è€…3: ä½è—¤ã§ã™ã€‚ãã®ä»¶ã«ã¤ã„ã¦ã€ã‚¤ãƒ³ãƒ•ãƒ©å´ã‹ã‚‰æ”¯æ´ã§ãã‚‹ã“ã¨ãŒã‚ã‚Šã¾ã™ã€‚æ¥é€±æœˆæ›œæ—¥ã¾ã§ã«ã€ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã®ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°ã‚’å®Ÿæ–½ã„ãŸã—ã¾ã™ã€‚

è©±è€…4: éˆ´æœ¨ã§ã™ã€‚ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°å´ã®æº–å‚™ã¯ã„ã‹ãŒã§ã—ã‚‡ã†ã‹ï¼Ÿ

è©±è€…5: é«˜æ©‹ã§ã™ã€‚ãƒãƒ¼ã‚±ãƒ†ã‚£ãƒ³ã‚°è³‡æ–™ã¯å®Œæˆã—ã¦ãŠã‚Šã€ãƒ©ãƒ³ãƒ‡ã‚£ãƒ³ã‚°ãƒšãƒ¼ã‚¸ã‚‚æ¥é€±ç«æ›œæ—¥ã«ã¯å…¬é–‹äºˆå®šã§ã™ã€‚åºƒå‘Šã‚­ãƒ£ãƒ³ãƒšãƒ¼ãƒ³ã®æº–å‚™ã‚‚æ•´ã£ã¦ãŠã‚Šã¾ã™ã€‚

è©±è€…1: ç´ æ™´ã‚‰ã—ã„ã§ã™ã­ã€‚ãã‚Œã§ã¯ã€æ¬¡å›ã®ä¼šè­°ã¯æ¥é€±é‡‘æ›œæ—¥ã®åŒã˜æ™‚é–“ã¨ã„ã†ã“ã¨ã§ã€æœ€çµ‚ç¢ºèªã‚’è¡Œã„ã¾ã—ã‚‡ã†ã€‚å„æ‹…å½“è€…ã¯ä»Šæ—¥æ±ºã‚ãŸã‚¢ã‚¯ã‚·ãƒ§ãƒ³é …ç›®ã‚’æ¥é€±ã¾ã§ã«å®Œäº†ã‚’ãŠé¡˜ã„ã—ã¾ã™ã€‚

è©±è€…2: æ‰¿çŸ¥ã„ãŸã—ã¾ã—ãŸã€‚

è©±è€…3: äº†è§£ã§ã™ã€‚

è©±è€…1: ãã‚Œã§ã¯ã€ä»Šæ—¥ã¯ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚ãŠç–²ã‚Œæ§˜ã§ã—ãŸã€‚"""

    def _generate_meeting_summary_with_specified_model(self, meeting_info: Dict[str, str], transcript_text: str, object_key: str) -> Optional[Dict[str, Any]]:
        """æŒ‡å®šãƒ¢ãƒ‡ãƒ« anthropic.claude-sonnet-4-20250514-v1:0 ã§Claudeè­°äº‹éŒ²ç”Ÿæˆ"""
        logger.info(f"ğŸ¤– Claudeè­°äº‹éŒ²ç”Ÿæˆé–‹å§‹")
        logger.info(f"ğŸ¥‡ æŒ‡å®šãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«: {self.primary_model}")
        
        # Claudeå‡¦ç†çŠ¶æ³ã‚’S3ã«è¨˜éŒ²
        filename = object_key.split('/')[-1].rsplit('.', 1)[0]
        claude_debug_key = f"email_output/{filename}/claude_processing.txt"
        
        # ãƒ†ã‚­ã‚¹ãƒˆé•·åˆ¶é™
        original_length = len(transcript_text)
        if len(transcript_text) > self.max_transcript_length:
            transcript_text = transcript_text[:self.max_transcript_length] + "\n\n...(æ–‡å­—æ•°åˆ¶é™ã«ã‚ˆã‚Šçœç•¥)"
            logger.info(f"ğŸ“ æ–‡å­—èµ·ã“ã—ã‚’ {self.max_transcript_length} æ–‡å­—ã«åˆ¶é™ (å…ƒ: {original_length}æ–‡å­—)")
        
        # æŒ‡å®šãƒ¢ãƒ‡ãƒ« anthropic.claude-sonnet-4-20250514-v1:0 ã§é †æ¬¡è©¦è¡Œ
        for i, model_id in enumerate(self.claude_models):
            try:
                if i == 0:
                    model_status = f"ğŸ¥‡ æŒ‡å®šãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«: {model_id}"
                else:
                    model_status = f"#{i+1} ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«: {model_id}"
                
                logger.info(f"ğŸ”„ Claude APIå‘¼ã³å‡ºã—: {model_status}")
                
                # è©³ç´°ãƒ—ãƒ­ãƒ³ãƒ—ãƒˆ
                prompt = f"""ä»¥ä¸‹ã®ä¼šè­°ã®æ–‡å­—èµ·ã“ã—ã‹ã‚‰ã€æ§‹é€ åŒ–ã•ã‚ŒãŸè­°äº‹éŒ²ã‚’ä½œæˆã—ã¦ãã ã•ã„ã€‚

ã€ä¼šè­°æƒ…å ±ã€‘
ä¼šè­°å: {meeting_info['title']}
æ—¥æ™‚: {meeting_info['date']}
å‚åŠ è€…: {meeting_info['participants']}

ã€æ–‡å­—èµ·ã“ã—å†…å®¹ã€‘
{transcript_text}

ã€å¿…é ˆå‡ºåŠ›å½¢å¼ã€‘
ä»¥ä¸‹ã®JSONå½¢å¼ã§å¿…ãšå›ç­”ã—ã¦ãã ã•ã„:

{{
"meeting_summary": "ä¼šè­°ã®è¦ç´„ã‚’2-3æ–‡ã§ç°¡æ½”ã«è¨˜è¿°ã—ã¦ãã ã•ã„",
"key_decisions": ["æ±ºå®šäº‹é …1", "æ±ºå®šäº‹é …2", "æ±ºå®šäº‹é …3"],
"action_items": [
{{
"task": "å…·ä½“çš„ãªã‚¿ã‚¹ã‚¯å†…å®¹ã‚’è¨˜è¿°",
"assignee": "æ‹…å½“è€…åï¼ˆä¸æ˜ãªå ´åˆã¯ã€Œè¦ç¢ºèªã€ã¨è¨˜è¼‰ï¼‰",
"deadline": "æœŸé™ï¼ˆä¸æ˜ãªå ´åˆã¯ã€Œè¦è¨­å®šã€ã¨è¨˜è¼‰ï¼‰",
"priority": "é«˜/ä¸­/ä½ã®ã„ãšã‚Œã‹ã‚’è¨­å®š"
}}
],
"next_meeting": "æ¬¡å›ä¼šè­°ã®äºˆå®šï¼ˆä¸æ˜ãªå ´åˆã¯ã€Œæœªå®šã€ã¨è¨˜è¼‰ï¼‰",
"concerns": ["æ‡¸å¿µäº‹é …1", "æ‡¸å¿µäº‹é …2"]
}}

ã€é‡è¦ãªæ³¨æ„äº‹é …ã€‘
1. å¿…ãšJSONã®æ§‹æ–‡ã‚’æ­£ã—ãå®ˆã£ã¦ãã ã•ã„
2. æ–‡å­—èµ·ã“ã—ã‹ã‚‰æ˜ç¢ºã«èª­ã¿å–ã‚Œã‚‹å†…å®¹ã®ã¿ã‚’è¨˜è¼‰ã—ã¦ãã ã•ã„
3. æ¨æ¸¬ã‚„è£œå®Œã¯é¿ã‘ã¦ãã ã•ã„
4. ã™ã¹ã¦æ—¥æœ¬èªã§å›ç­”ã—ã¦ãã ã•ã„
5. JSONã®å¤–ã«èª¬æ˜æ–‡ã¯å«ã‚ãªã„ã§ãã ã•ã„"""

                # Claude APIå‘¼ã³å‡ºã—ï¼ˆæŒ‡å®šãƒ¢ãƒ‡ãƒ«å„ªå…ˆï¼‰
                body = json.dumps({
                    "anthropic_version": "bedrock-2023-05-31",
                    "max_tokens": 4000,
                    "temperature": 0.1,
                    "messages": [{"role": "user", "content": prompt}]
                })

                logger.info(f"ğŸ“¡ Bedrock APIå‘¼ã³å‡ºã—å®Ÿè¡Œ: {model_id}")
                
                response = self.bedrock_client.invoke_model(
                    modelId=model_id,
                    body=body,
                    contentType="application/json"
                )

                response_body = json.loads(response['body'].read())
                content = response_body['content'][0]['text']
                
                logger.info(f"âœ… Claude ãƒ¬ã‚¹ãƒãƒ³ã‚¹å—ä¿¡: {len(content)}æ–‡å­—")
                logger.info(f"ä½¿ç”¨æˆåŠŸãƒ¢ãƒ‡ãƒ«: {model_id}")
                
                # JSONè§£æ
                parsed_result = self._parse_claude_response(content)
                
                if parsed_result:
                    # æˆåŠŸ - è©³ç´°ãƒ‡ãƒãƒƒã‚°æƒ…å ±ã‚’S3ã«ä¿å­˜
                    success_debug_content = f"""=== Claude API æˆåŠŸ ===

å‡¦ç†æ™‚åˆ»: {datetime.now().isoformat()}
éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«: {object_key}

ğŸ¥‡ ä½¿ç”¨æˆåŠŸãƒ¢ãƒ‡ãƒ«: {model_id}
ãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹: {model_status}
è©¦è¡Œå›æ•°: {i+1}/{len(self.claude_models)}

å‡¦ç†è©³ç´°:
- å…¥åŠ›æ–‡å­—æ•°: {original_length}æ–‡å­— (ä½¿ç”¨: {len(transcript_text)}æ–‡å­—)
- å‡ºåŠ›æ–‡å­—æ•°: {len(content)}æ–‡å­—
- JSONè§£æ: âœ… æˆåŠŸ

ä¼šè­°æƒ…å ±:
- ã‚¿ã‚¤ãƒˆãƒ«: {meeting_info['title']}
- æ—¥æ™‚: {meeting_info['date']}

ç”Ÿæˆã•ã‚ŒãŸè­°äº‹éŒ²:
{json.dumps(parsed_result, ensure_ascii=False, indent=2)}

Claude ãƒ¬ã‚¹ãƒãƒ³ã‚¹ (Raw):
{content}
"""

                    self.s3_client.put_object(
                        Bucket="followup-mail",
                        Key=claude_debug_key,
                        Body=success_debug_content.encode('utf-8'),
                        ContentType='text/plain; charset=utf-8'
                    )
                    
                    logger.info(f"âœ… Claude APIæˆåŠŸ: {model_status}")
                    return parsed_result
                else:
                    # JSONè§£æå¤±æ•— - æ¬¡ã®ãƒ¢ãƒ‡ãƒ«ã‚’è©¦è¡Œ
                    logger.warning(f"âš ï¸ JSONè§£æå¤±æ•—: {model_status} - æ¬¡ã®ãƒ¢ãƒ‡ãƒ«ã‚’è©¦è¡Œ")
                    continue
                
            except Exception as e:
                error_type = type(e).__name__
                logger.warning(f"âš ï¸ Claude API ã‚¨ãƒ©ãƒ¼: {model_status} - {error_type}: {str(e)}")
                
                # ã‚¨ãƒ©ãƒ¼è©³ç´°ã‚’S3ã«ä¿å­˜
                error_debug_content = f"""=== Claude API ã‚¨ãƒ©ãƒ¼è©³ç´° ===

å‡¦ç†æ™‚åˆ»: {datetime.now().isoformat()}
éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«: {object_key}

âŒ å¤±æ•—ãƒ¢ãƒ‡ãƒ«: {model_id}
ãƒ¢ãƒ‡ãƒ«çŠ¶æ…‹: {model_status}
è©¦è¡Œå›æ•°: {i+1}/{len(self.claude_models)}
ã‚¨ãƒ©ãƒ¼ç¨®é¡: {error_type}
ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {str(e)}

ã€ã“ã®ã‚¨ãƒ©ãƒ¼ã®å¯¾å‡¦æ³•ã€‘
"""

                if "AccessDenied" in str(e):
                    error_debug_content += f"""
ã“ã®ãƒ¢ãƒ‡ãƒ«ã¯Bedrockã§ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãŒã‚ã‚Šã¾ã›ã‚“ã€‚

è§£æ±ºæ‰‹é †:
1. AWS Bedrock ã‚³ãƒ³ã‚½ãƒ¼ãƒ« â†’ Model access
2. {model_id} ã‚’æ¤œç´¢
3. Statusç¢ºèª:
   - 'Access granted' â†’ ä½¿ç”¨å¯èƒ½ (ã“ã®ã‚¨ãƒ©ãƒ¼ã¯åˆ¥ã®åŸå› )
   - 'Available to request' â†’ ä»¥ä¸‹ã®æ‰‹é †ã§ç”³è«‹:
     a) 'Request model access' ã‚’ã‚¯ãƒªãƒƒã‚¯
     b) Use case: 'General' ã‚’é¸æŠ
     c) Submit
     d) æ‰¿èªã¾ã§æ•°åˆ†ã€œæ•°æ™‚é–“å¾…æ©Ÿ
4. æ‰¿èªå¾Œã€MP3ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
"""
                else:
                    error_debug_content += f"""
äºˆæœŸã—ãªã„ã‚¨ãƒ©ãƒ¼ã§ã™ã€‚
åŸå› ã¨ã—ã¦è€ƒãˆã‚‰ã‚Œã‚‹ã‚‚ã®:
- ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯å•é¡Œ
- ä¸€æ™‚çš„ãªã‚µãƒ¼ãƒ“ã‚¹å•é¡Œ
- ãƒªã‚¯ã‚¨ã‚¹ãƒˆå½¢å¼ã®å•é¡Œ

æ¬¡ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã§å†è©¦è¡Œã—ã¾ã™ã€‚
"""

                error_debug_content += f"\næ¬¡ã®å¯¾å¿œ: {'æ¬¡ã®ãƒ¢ãƒ‡ãƒ«ã§å†è©¦è¡Œ' if i < len(self.claude_models)-1 else 'ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨'}"
                
                # S3ã«ã‚¨ãƒ©ãƒ¼ãƒ­ã‚°ä¿å­˜
                self.s3_client.put_object(
                    Bucket="followup-mail",
                    Key=claude_debug_key,
                    Body=error_debug_content.encode('utf-8'),
                    ContentType='text/plain; charset=utf-8'
                )
        
        # å…¨ãƒ¢ãƒ‡ãƒ«å¤±æ•—
        logger.error(f"âŒ å…¨ãƒ¢ãƒ‡ãƒ«å¤±æ•— - ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ä½¿ç”¨")
        return None

    def _parse_claude_response(self, content: str) -> Optional[Dict[str, Any]]:
        """Claude ãƒ¬ã‚¹ãƒãƒ³ã‚¹è§£æ"""
        try:
            # JSONã®é–‹å§‹ã¨çµ‚äº†ã‚’æ¤œç´¢
            start_idx = content.find('{')
            end_idx = content.rfind('}') + 1
            
            if start_idx == -1 or end_idx <= 0 or end_idx <= start_idx:
                logger.warning("âš ï¸ JSONå½¢å¼ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
                return None
            
            json_content = content[start_idx:end_idx]
            return json.loads(json_content)
            
        except json.JSONDecodeError as e:
            logger.error(f"âŒ JSONè§£æã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None
        except Exception as e:
            logger.error(f"âŒ è§£æã‚¨ãƒ©ãƒ¼: {str(e)}")
            return None

    def _create_demo_summary(self, meeting_info: Dict[str, str], transcript_text: str) -> Dict[str, Any]:
        """ãƒ‡ãƒ¢è­°äº‹éŒ²ä½œæˆï¼ˆæŒ‡å®šãƒ¢ãƒ‡ãƒ«å¤±æ•—æ™‚ã®ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ï¼‰"""
        logger.info(f"ğŸ“ ãƒ‡ãƒ¢è­°äº‹éŒ²ä½œæˆ (æŒ‡å®šãƒ¢ãƒ‡ãƒ« {self.primary_model} ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™å•é¡Œ)")
        
        return {
            "meeting_summary": f"{meeting_info['title']}ã‚’é–‹å‚¬ã—ã¾ã—ãŸã€‚éŸ³å£°ã‹ã‚‰æ–‡å­—èµ·ã“ã—ã‚’å®Ÿè¡Œã—ã€æŒ‡å®šã®Claude ãƒ¢ãƒ‡ãƒ« ({self.primary_model}) ã§ã®è­°äº‹éŒ²ç”Ÿæˆã‚’è©¦è¡Œã—ã¾ã—ãŸãŒã€Bedrockã®ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™å•é¡Œã®ãŸã‚ã€ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ã§çµæœã‚’ç”Ÿæˆã—ã¦ã„ã¾ã™ã€‚",
            "key_decisions": [
                "éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰æ–‡å­—èµ·ã“ã—ã‚’å®Œäº†",
                "æŒ‡å®šClaude ãƒ¢ãƒ‡ãƒ«ã§ã®è­°äº‹éŒ²ç”Ÿæˆã‚’è©¦è¡Œ",
                "Bedrockãƒ¢ãƒ‡ãƒ«ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ã®å•é¡Œã‚’ç¢ºèª",
                "ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ã§æš«å®šçµæœã‚’å‡ºåŠ›"
            ],
            "action_items": [
                {
                    "task": f"AWS Bedrockã§æŒ‡å®šãƒ¢ãƒ‡ãƒ« ({self.primary_model}) ã®ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ç”³è«‹",
                    "assignee": "ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…",
                    "deadline": "è¦è¨­å®š",
                    "priority": "é«˜"
                },
                {
                    "task": "æ–‡å­—èµ·ã“ã—å†…å®¹ã®æ‰‹å‹•ç¢ºèªã¨æ­£å¼ãªè­°äº‹éŒ²ä½œæˆ",
                    "assignee": "å‚åŠ è€…å…¨å“¡",
                    "deadline": "è¦è¨­å®š",
                    "priority": "é«˜"
                },
                {
                    "task": "ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«ã®ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ç¢ºèª",
                    "assignee": "ã‚·ã‚¹ãƒ†ãƒ ç®¡ç†è€…",
                    "deadline": "è¦è¨­å®š",
                    "priority": "ä¸­"
                }
            ],
            "next_meeting": "æœªå®šï¼ˆå‚åŠ è€…ã§èª¿æ•´ï¼‰",
            "concerns": [
                f"æŒ‡å®šãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ« ({self.primary_model}) ã®ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãªã—",
                f"å…¨ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ‡ãƒ« ({len(self.claude_models)-1}å€‹) ã§ã‚‚ã‚¢ã‚¯ã‚»ã‚¹æ‹’å¦",
                "AWS Bedrock Model access ã§ã®ç”³è«‹ãƒ»æ‰¿èªãŒå¿…è¦",
                "æš«å®šçš„ã«ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ã§å‡ºåŠ›ä¸­"
            ],
            "specified_model": self.primary_model,
            "model_access_status": "Access Denied - ç”³è«‹ãŒå¿…è¦",
            "technical_note": f"æŒ‡å®šãƒ¢ãƒ‡ãƒ« '{self.primary_model}' (Claude Sonnet 4) ã‚’æœ€å„ªå…ˆã§è©¦è¡Œã—ãŸãŒã€å…¨{len(self.claude_models)}ãƒ¢ãƒ‡ãƒ«ã§AccessDenied",
            "note": f"ã“ã®è­°äº‹éŒ²ã¯æŒ‡å®šãƒ¢ãƒ‡ãƒ« {self.primary_model} ã®ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™å•é¡Œæ™‚ã®ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ã§ã™ã€‚Bedrockã§ãƒ¢ãƒ‡ãƒ«ã‚¢ã‚¯ã‚»ã‚¹ç”³è«‹å¾Œã«å†å®Ÿè¡Œã—ã¦ãã ã•ã„ã€‚"
        }

    def _create_copy_paste_text(self, summary_result: Dict[str, Any], meeting_info: Dict[str, str], source_file: str, transcript_text: str) -> str:
        """ãƒ¡ãƒ¼ãƒ«ã‚³ãƒ”ãƒšç”¨ãƒ†ã‚­ã‚¹ãƒˆä½œæˆ - æ–°ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        # ãƒ¡ãƒ¼ãƒ«ä»¶åç”¨ã®æ—¥ä»˜æ•´å½¢
        meeting_date = meeting_info['date']
        if 'å¹´' in meeting_date and 'æœˆ' in meeting_date and 'æ—¥' in meeting_date:
            try:
                # ã€Œ2025å¹´9æœˆ26æ—¥ 18:50ã€å½¢å¼ã‹ã‚‰ã€Œ9/26ã€å½¢å¼ã«å¤‰æ›
                date_parts = meeting_date.split(' ')[0].split('å¹´')
                month = date_parts[1].split('æœˆ')[0]
                day = date_parts[1].split('æœˆ')[1].split('æ—¥')[0]
                short_date = f"{month}/{day}"
            except:
                short_date = meeting_date
        else:
            short_date = meeting_date

        # ä¼šè­°æ¦‚è¦ã®æ•´å½¢
        meeting_summary = summary_result.get('meeting_summary', '').strip()

        # é‡è¦ãªæ±ºå®šäº‹é …
        key_decisions = []
        for decision in summary_result.get('key_decisions', []):
            if decision and decision.strip():
                key_decisions.append(decision.strip())

        # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³é …ç›®
        action_items = []
        for item in summary_result.get('action_items', []):
            task = item.get('task', '').strip()
            assignee = item.get('assignee', 'è¦ç¢ºèª').strip()
            deadline = item.get('deadline', 'æœªå®š').strip()
            
            if task:
                deadline_text = ""
                if deadline and deadline != "è¦è¨­å®š" and deadline != "æœªå®š":
                    deadline_text = f"ï¼ˆæœŸé™ï¼š{deadline}ï¼‰"
                
                action_items.append(f"{assignee}ï¼š {task}{deadline_text}")

        # ãƒ¡ãƒ¼ãƒ«æœ¬æ–‡ä½œæˆ
        email_body = f"""ä»¶åï¼šæœ¬æ—¥ã®ãŠæ‰“ã¡åˆã‚ã›ã®ãŠç¤¼ã¨å†…å®¹ã®ã”å…±æœ‰

ã”æ‹…å½“è€…æ§˜

æœ¬æ—¥ã¯ãŠå¿™ã—ã„ä¸­ã€ãƒŸãƒ¼ãƒ†ã‚£ãƒ³ã‚°ã«ã”å‚åŠ ã„ãŸã ãèª ã«ã‚ã‚ŠãŒã¨ã†ã”ã–ã„ã¾ã—ãŸã€‚
æœ¬æ—¥ã®å†…å®¹ã‚’ä»¥ä¸‹ã®é€šã‚Šã”å…±æœ‰ã„ãŸã—ã¾ã™ã€‚

â¸»

è­°äº‹éŒ²ï¼ˆSummaryï¼‰
"""

        # ä¼šè­°æ¦‚è¦
        if meeting_summary:
            email_body += f"\tâ€¢ {meeting_summary}\n"

        # é‡è¦ãªæ±ºå®šäº‹é …
        if key_decisions:
            for point in key_decisions:
                email_body += f"\tâ€¢ {point}\n"
        else:
            email_body += "\tâ€¢ ç‰¹ã«æ±ºå®šäº‹é …ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ\n"

        # ã‚¢ã‚¯ã‚·ãƒ§ãƒ³é …ç›®
        email_body += "\næ¬¡ã®ã‚¢ã‚¯ã‚·ãƒ§ãƒ³ï¼ˆNext Actionï¼‰"
        if action_items:
            for action in action_items:
                email_body += f"\n\tâ€¢ {action}"
        else:
            email_body += "\n\tâ€¢ ç‰¹ã«ã‚¢ã‚¯ã‚·ãƒ§ãƒ³é …ç›®ã¯ã‚ã‚Šã¾ã›ã‚“ã§ã—ãŸ"

        # ãƒ¡ãƒ¼ãƒ«ç· ã‚
        email_body += """

â¸»

å†…å®¹ã«èª¤ã‚Šã‚„è¿½åŠ äº‹é …ãŒã”ã–ã„ã¾ã—ãŸã‚‰ã€ã”æŒ‡æ‘˜ã„ãŸã ã‘ã¾ã™ã¨å¹¸ã„ã§ã™ã€‚
å¼•ãç¶šãã©ã†ãã‚ˆã‚ã—ããŠé¡˜ã„ç”³ã—ä¸Šã’ã¾ã™ã€‚

"""

        # ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ã®å ´åˆã¯ã‚·ã‚¹ãƒ†ãƒ ä½¿ç”¨æƒ…å ±ã‚’è¿½åŠ 
        is_demo = "note" in summary_result
        if is_demo:
            email_body += f"\nâ€» è­°äº‹éŒ²ã¯éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰è‡ªå‹•ç”Ÿæˆã•ã‚Œã¾ã—ãŸã€‚"
            email_body += f"\nâ€» ç¾åœ¨ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ä¸­ã§ã™ã€‚AWS Bedrockã§ {self.primary_model} ã®ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ç”³è«‹ãŒå¿…è¦ã§ã™ã€‚"
        
        return email_body

    def _save_text_files_to_email_output(self, bucket_name: str, object_key: str, transcript_text: str, 
                                    summary_result: Dict[str, Any], copy_paste_text: str) -> Dict[str, str]:
        """
        Save output files to S3 with an organized folder structure and manifest
        
        Returns a dictionary of file paths created
        """
        try:
            # Extract filename without extension for folder name
            audio_filename = object_key.split('/')[-1].rsplit('.', 1)[0]
            timestamp = datetime.now().strftime('%Y%m%d%H%M%S')
            job_id = f"{audio_filename}_{timestamp}"
            
            # Create subfolder path
            output_folder = f"email_output/{audio_filename}/"
            
            # Define standard filenames without timestamps
            files_to_save = [
                # Main content files with standardized names
                (f"{output_folder}email_content.txt", copy_paste_text, 'text/plain; charset=utf-8'),
                (f"{output_folder}transcript.txt", transcript_text, 'text/plain; charset=utf-8'),
                (f"{output_folder}summary.json", json.dumps(summary_result, ensure_ascii=False, indent=2), 'application/json; charset=utf-8'),
            ]
            
            # Save files
            saved_files = {}
            for key, content, content_type in files_to_save:
                self.s3_client.put_object(
                    Bucket=bucket_name,
                    Key=key,
                    Body=content.encode('utf-8') if isinstance(content, str) else content,
                    ContentType=content_type
                )
                saved_files[key.split('/')[-1].rsplit('.', 1)[0]] = key
                logger.info(f"ğŸ’¾ ä¿å­˜å®Œäº†: s3://{bucket_name}/{key}")
            
            # Create manifest file with all metadata
            is_demo = "note" in summary_result
            processed_at = datetime.now().isoformat()
            
            manifest = {
                "status": "success",
                "job_id": job_id,
                "source": {
                    "file": object_key,
                    "processed_at": processed_at
                },
                "meeting": {
                    "title": summary_result.get("meeting_title", "Meeting Recording"),
                    "date": summary_result.get("meeting_date", processed_at),
                    "participants": summary_result.get("participants", "Automatically detected")
                },
                "processing": {
                    "transcript_length": len(transcript_text),
                    "model_used": self.primary_model,
                    "is_demo_data": is_demo
                },
                "files": {
                    "transcript": f"{output_folder}transcript.txt",
                    "email_content": f"{output_folder}email_content.txt",
                    "summary_json": f"{output_folder}summary.json",
                    "progress_log": f"{output_folder}progress.txt"
                },
                # Include the full summary directly in the manifest
                "summary": summary_result
            }
            
            # Save manifest file
            manifest_key = f"{output_folder}manifest.json"
            self.s3_client.put_object(
                Bucket=bucket_name,
                Key=manifest_key,
                Body=json.dumps(manifest, ensure_ascii=False, indent=2).encode('utf-8'),
                ContentType='application/json; charset=utf-8'
            )
            saved_files["manifest"] = manifest_key
            logger.info(f"ğŸ“‹ ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆä½œæˆ: s3://{bucket_name}/{manifest_key}")
            
            # Create index file at the root of email_output to help frontend find latest results
            self._update_index_file(bucket_name, audio_filename, manifest)
            
            logger.info(f"âœ… å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜å®Œäº†: {output_folder}")
            return saved_files
            
        except Exception as e:
            logger.error(f"âŒ ãƒ•ã‚¡ã‚¤ãƒ«ä¿å­˜ã‚¨ãƒ©ãƒ¼: {str(e)}", exc_info=True)
            return {}

    def _update_index_file(self, bucket_name: str, audio_filename: str, manifest: Dict[str, Any]) -> None:
        """
        Create or update an index file that lists all processed recordings
        This helps the frontend find the latest processed files
        """
        try:
            index_key = "email_output/index.json"
            
            # Try to read existing index
            try:
                response = self.s3_client.get_object(Bucket=bucket_name, Key=index_key)
                index_data = json.loads(response['Body'].read().decode('utf-8'))
            except:
                index_data = {
                    "processed_files": {},
                    "last_updated": datetime.now().isoformat()
                }
            
            # Add or update entry for this audio file
            index_data["processed_files"][audio_filename] = {
                "manifest_path": f"email_output/{audio_filename}/manifest.json",
                "processed_at": manifest["source"]["processed_at"],
                "title": manifest["meeting"]["title"],
                "status": manifest["status"]
            }
            index_data["last_updated"] = datetime.now().isoformat()
            
            # Save updated index
            self.s3_client.put_object(
                Bucket=bucket_name,
                Key=index_key,
                Body=json.dumps(index_data, ensure_ascii=False, indent=2).encode('utf-8'),
                ContentType='application/json; charset=utf-8'
            )
            logger.info(f"ğŸ“‘ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ›´æ–°: s3://{bucket_name}/{index_key}")
            
        except Exception as e:
            logger.warning(f"âš ï¸ ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹æ›´æ–°å¤±æ•—: {str(e)}")

    def _create_completion_notification(self, bucket_name: str, object_key: str, meeting_info: Dict[str, str], 
                                   transcript_length: int, saved_files: Dict[str, str]) -> None:
        """
        Create a completion notification file in the audio's subfolder
        """
        try:
            audio_filename = object_key.split('/')[-1].rsplit('.', 1)[0]
            notification_key = f"email_output/{audio_filename}/status.txt"
            
            # Check if we're using demo data
            manifest_key = saved_files.get("manifest", "")
            if manifest_key:
                try:
                    response = self.s3_client.get_object(Bucket=bucket_name, Key=manifest_key)
                    manifest = json.loads(response['Body'].read().decode('utf-8'))
                    is_demo = manifest.get("processing", {}).get("is_demo_data", False)
                except:
                    is_demo = False
            else:
                is_demo = False
            
            notification_content = f"""=== è­°äº‹éŒ²ç”Ÿæˆå®Œäº† ===

å®Œäº†æ™‚åˆ»: {datetime.now().strftime('%Yå¹´%mæœˆ%dæ—¥ %H:%M:%S')}
éŸ³å£°ãƒ•ã‚¡ã‚¤ãƒ«: {object_key}
ä¼šè­°ã‚¿ã‚¤ãƒˆãƒ«: {meeting_info['title']}

ğŸ“‹ ãƒ•ã‚¡ã‚¤ãƒ«å ´æ‰€:
s3://{bucket_name}/email_output/{audio_filename}/

ğŸ§© ä¸»è¦ãƒ•ã‚¡ã‚¤ãƒ«:
â€¢ manifest.json - ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰ç”¨ãƒãƒ‹ãƒ•ã‚§ã‚¹ãƒˆï¼ˆæœ€é‡è¦ï¼‰
â€¢ email_content.txt - ãƒ¡ãƒ¼ãƒ«ã‚³ãƒ”ãƒšç”¨ãƒ†ã‚­ã‚¹ãƒˆ
â€¢ transcript.txt - æ–‡å­—èµ·ã“ã—å…¨æ–‡
â€¢ summary.json - è­°äº‹éŒ²ãƒ‡ãƒ¼ã‚¿ (JSONå½¢å¼)

ğŸ’» ãƒ•ãƒ­ãƒ³ãƒˆã‚¨ãƒ³ãƒ‰è¡¨ç¤º:
manifest.json ãƒ•ã‚¡ã‚¤ãƒ«ã‚’å‚ç…§ã—ã¦ãã ã•ã„ã€‚
"""

            if is_demo:
                notification_content += f"""
âš ï¸ æ³¨æ„:
æŒ‡å®šãƒ¢ãƒ‡ãƒ« ({self.primary_model}) ã®ã‚¢ã‚¯ã‚»ã‚¹æ¨©é™ãŒãªã„ãŸã‚ã€
ãƒ‡ãƒ¢ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ã„ã¾ã™ã€‚AWS Bedrockã§ãƒ¢ãƒ‡ãƒ«ã‚¢ã‚¯ã‚»ã‚¹ã‚’ç”³è«‹ã—ã¦ãã ã•ã„ã€‚
"""

            self.s3_client.put_object(
                Bucket=bucket_name,
                Key=notification_key,
                Body=notification_content.encode('utf-8'),
                ContentType='text/plain; charset=utf-8'
            )
            
            logger.info(f"ğŸ“¢ å®Œäº†é€šçŸ¥ä½œæˆ: s3://{bucket_name}/{notification_key}")
            
        except Exception as e:
            logger.warning(f"âš ï¸ å®Œäº†é€šçŸ¥ä½œæˆå¤±æ•—: {str(e)}")

    def _create_error_debug_file(self, error_message: str, exception: Exception) -> None:
        """ã‚¨ãƒ©ãƒ¼æ™‚ã®ãƒ‡ãƒãƒƒã‚°ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ"""
        try:
            timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
            error_key = f"system_logs/SYSTEM_ERROR_{timestamp}.txt"
            
            import traceback
            error_content = f"""=== ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼æƒ…å ± ===

ç™ºç”Ÿæ™‚åˆ»: {datetime.now().isoformat()}
ã‚¨ãƒ©ãƒ¼ãƒ¡ãƒƒã‚»ãƒ¼ã‚¸: {error_message}

ğŸ¥‡ æŒ‡å®šãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«: {self.primary_model}
ğŸ”„ ãƒ•ã‚©ãƒ¼ãƒ«ãƒãƒƒã‚¯ãƒ¢ãƒ‡ãƒ«æ•°: {len(self.claude_models) - 1}

è©³ç´°ãƒˆãƒ¬ãƒ¼ã‚¹ãƒãƒƒã‚¯:
{traceback.format_exc()}

ã€Bedrockè¨­å®šç¢ºèªãƒªã‚¹ãƒˆã€‘
AWS Bedrock â†’ Model access ã§ä»¥ä¸‹ã‚’ç¢ºèª:

æœ€é‡è¦:
â–¡ {self.primary_model} â† æŒ‡å®šã•ã‚ŒãŸãƒ¡ã‚¤ãƒ³ãƒ¢ãƒ‡ãƒ«
"""

            for model in self.claude_models[1:]:
                error_content += f"â–¡ {model}\n"
            
            error_content += f"""

ã€Status ã®æ„å‘³ã€‘
â€¢ 'Access granted' â†’ ä½¿ç”¨å¯èƒ½
â€¢ 'Available to request' â†’ ç”³è«‹ãŒå¿…è¦
â€¢ ãã®ä»– â†’ åˆ©ç”¨ä¸å¯

ã€ç”³è«‹æ‰‹é †ã€‘
1. 'Available to request' ã®ãƒ¢ãƒ‡ãƒ«ã‚’ã‚¯ãƒªãƒƒã‚¯
2. 'Request model access' ã‚’ã‚¯ãƒªãƒƒã‚¯
3. Use case: 'General' ã‚’é¸æŠ
4. Submit
5. æ‰¿èªã¾ã§æ•°åˆ†ã€œæ•°æ™‚é–“å¾…æ©Ÿ
6. 'Access granted' ã«ãªã£ãŸã‚‰MP3å†ã‚¢ãƒƒãƒ—ãƒ­ãƒ¼ãƒ‰
"""

            self.s3_client.put_object(
                Bucket="followup-mail",
                Key=error_key,
                Body=error_content.encode('utf-8'),
                ContentType='text/plain; charset=utf-8'
            )
            logger.info(f"ğŸš¨ ã‚·ã‚¹ãƒ†ãƒ ã‚¨ãƒ©ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆ: s3://followup-mail/{error_key}")
            
        except Exception as e:
            logger.error(f"ã‚¨ãƒ©ãƒ¼ãƒ•ã‚¡ã‚¤ãƒ«ä½œæˆå¤±æ•—: {str(e)}")

    def _create_error_response(self, message: str, status_code: int = 500) -> Dict[str, Any]:
        """ã‚¨ãƒ©ãƒ¼ãƒ¬ã‚¹ãƒãƒ³ã‚¹ä½œæˆ"""
        return {
            'statusCode': status_code,
            'body': json.dumps({
                'status': 'error',
                'message': message,
                'specified_model': self.primary_model,
                'timestamp': datetime.now().isoformat()
            }, ensure_ascii=False)
        }

    def _create_file_error_result(self, object_key: str, error_message: str) -> Dict[str, Any]:
        """ãƒ•ã‚¡ã‚¤ãƒ«å‡¦ç†ã‚¨ãƒ©ãƒ¼çµæœä½œæˆ"""
        return {
            'file': object_key,
            'status': 'error',
            'error': error_message,
            'specified_model': self.primary_model,
            'timestamp': datetime.now().isoformat()
        }

    def _create_success_response(self, results: List[Dict[str, Any]]) -> Dict[str, Any]:
        """æˆåŠŸãƒ¬ã‚¹ãƒãƒ³ã‚¹ä½œæˆ"""
        successful_files = [r for r in results if r['status'] == 'success']
        failed_files = [r for r in results if r['status'] == 'error']

        return {
            'statusCode': 200,
            'body': json.dumps({
                'message': f'å‡¦ç†å®Œäº†: æˆåŠŸ {len(successful_files)}ä»¶, å¤±æ•— {len(failed_files)}ä»¶',
                'specified_model': self.primary_model,
                'summary': {
                    'total_files': len(results),
                    'successful': len(successful_files),
                    'failed': len(failed_files)
                },
                'results': results,
                'timestamp': datetime.now().isoformat()
            }, ensure_ascii=False, indent=2)
        }

# Lambda ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ
def lambda_handler(event: Dict[str, Any], context: Any) -> Dict[str, Any]:
    """Lambdaé–¢æ•°ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆ"""
    processor = MeetingMinutesProcessor()
    return processor.process_event(event, context)
